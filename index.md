---
layout: custom
---

# What and How of Machine Learning Transparency #
### Building Bespoke Explainability Tools with Interoperable Algorithmic Components ###
A hands-on tutorial to be held at the
[ECML-PKDD 2020](https://ecmlpkdd2020.net/) conference in Ghent, Belgium, from
the 14th to the 18th of September 2020.

## Tutorial Outline ##
In this hands-on tutorial we will introduce popular transparency,
interpretability and explainability tools; explain their strengths and
weaknesses; demonstrate how to identify their interoperable
*algorithmic components*; and decompose them into these atomic functional
blocks. We will then teach participants how to improve upon off-the-shelf
solutions by taking advantage of this modularity and building a suite of
bespoke transparency forensic tools for a predictive pipeline: data (both raw
and features), models and predictions. This effort will be grounded with a
theoretical introduction followed by interactive coding exercises, supporting
two distinct goals: research & development, and deployment of such tools. The
major hands-on part of the tutorial will therefore walk the attendees through
*building* and *validating* their own *transparency tools*, for example,
composing a custom surrogate explainer and adjusting a counterfactual data
point generator for black-box predictions. To this end, we will use
[`FAT Forensics`](https://fat-forensics.org/) -- a Python toolbox open-sourced
under the BSD 3-Clause license and designed to inspect fairness, accountability
and transparency (FAT) of all components of a predictive pipeline.

---

**More details and hands-on materials needed to participate in the tutorial
will be posted here closer to the tutorial date.**
