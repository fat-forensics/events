[![GitHub Pages](https://img.shields.io/badge/view-page-green.svg)](https://events.fat-forensics.org/)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4035128.svg)](https://doi.org/10.5281/zenodo.4035128)

# FAT Forensics Events #

This repository hosts <https://events.fat-forensics.org>, which holds details
of past and upcoming events such as workshops and (hands-on) tutorials run with
the [FAT Forensics](https://fat-forensics.org) package.

Dedicated Slack Workspace:
[![Chat via Slack](https://img.shields.io/badge/slack-FAT%20Forensics%20events-yellow.svg?logo=slack)](https://fatforensicsevents.slack.com/)

# History #

## November 2022 -- University of New South Wales ##

> **Never Let the Truth Get in the Way of a Good Story: The Importance of Multilevel Human Understanding in Explainable Artificial Intelligence**

An interactive presentation given at the *University of New South Wales*
(UNSW), discussing different levels at which explainability techniques and
their insights need to be understood
(using the example of surrogate explainers).

* [Slides](resources/2022_UNSW/slides/)

For more details please see the event homepage:
<https://events.fat-forensics.org/2022_unsw>.

## October 2022 -- ETH Z&uuml;rich ##

> **Mind the Gap! Bridging Explainable Artificial Intelligence and Human Understanding**

An interactive presentation given at *ETH Z&uuml;rich*, discussing how to
interpret and understand insights generated with surrogate explainers.

* [Slides](resources/2022_ETH/slides/)

For more details please see the event homepage:
<https://events.fat-forensics.org/2022_eth>.

## October 2022 -- Universit&agrave; della Svizzera italiana ##

> **Mind the Gap! Bridging Explainable Artificial Intelligence and Human Understanding**

An interactive presentation given at
*Universit&agrave; della Svizzera italiana*, discussing how to interpret and
understand insights generated with surrogate explainers.

* [Slides](resources/2022_USI/slides/)

For more details please see the event homepage:
<https://events.fat-forensics.org/2022_usi>.

## July 2022 -- AI and Humanity Summer Cluster ##

> **Where Does the Understanding Come From When Explaining Automated Decision-making Systems?**

An interactive presentation for the *AI and Humanity* summer cluster workshop,
discussing how machine learning explainers can help humans to understand
automated decision-making.

* [Slides](resources/2022_simons-institute/slides/)

For more details please see the event homepage:
<https://events.fat-forensics.org/2022_simons-institute>.

## March 2022 -- RMIT Lectorial ##

> **Transparency and Explainability**  
  *The AI/Data Science Professional Lectorial (2022, RMIT University)*

An overview of surrogate explainers for the 2022 *AI/Data Science Professional*
RMIT lectorial.

* [Slides](resources/2022_RMIT-lectorial/slides/)
* [Demonstration](https://github.com/fat-forensics/resources/tree/master/tabular_surrogate_builder)

For more details please see the event homepage:
<https://events.fat-forensics.org/2022_rmit-lectorial>.

## September 2021 -- TAILOR Summer School ##

> **What and How of Machine Learning Transparency:**  
  *Building Bespoke Explainability Tools with Interoperable Algorithmic Components*

A summer school session with a hands-on component organised at the
[2021 TAILOR Summer School](https://tailor-network.eu/summer-school-2021/)
held virtually between the 23rd and the 24th of September 2021.

* [Jupyter Notebook](https://github.com/fat-forensics/resources/tree/master/tabular_surrogate_builder)
* [Slides](resources/2021_TAILOR-summer-school/slides/)

For more details please see the event homepage:
<https://events.fat-forensics.org/2021_tailor-summer-school>.

## September 2021 -- BIAS Summer School ##

> **Practical Machine Learning Explainability:**  
  *Surrogate Explainers and Fairwashing*

A summer school session with a hands-on component organised at the
[2021 Bristol Interactive AI Summer School (BIAS)](https://www.bristol.ac.uk/cdt/interactive-ai/events/bias-summer-school/)
held between the 2nd and the 7th of September 2021.

* [Jupyter Notebook](https://github.com/fat-forensics/resources/tree/master/tabular_surrogate_builder)
* [Slides](resources/2021_BIAS-summer-school/slides/)

For more details please see the event homepage:
<https://events.fat-forensics.org/2021_bias>.

## September 2021 -- TAILOR Workpackage 3 ##

> **Do You Trust Your Explainer?**

An interactive presentation for *Workpackage 3* of the TAILOR project.

* [Slides](resources/2021_TAILOR-WP3/slides/)

For more details please see the event homepage:
<https://events.fat-forensics.org/2021_tailor-wp3>.

## August 2021 -- ADM+S Talk ##

> **Making Machine Learning Explanations Truthful and Intelligible**

An invited talk for the **Machines Programme** of the
*ARC Centre of Excellence for Automated Decision-Making and Society*
(ADM+S).

* [Slides](resources/2021_ADMS/slides/)

For more details please see the event homepage:
<https://events.fat-forensics.org/2021_adms>.

## July 2021 -- EURO Talk ##

> **Making Machine Learning Explanations Truthful and Intelligible**

An invited talk for the special session on **Fair and Explainable Models**
held at the 31st European Conference on Operational Research (2021).

* [Slides](resources/2021_EURO-explainability/slides/)

For more details please see the event homepage:
<https://events.fat-forensics.org/2021_euro-explainability>.

## March 2021 -- The Alan Turing Institute AI UK Demonstration ##

> **Did You Get That?**  
> *Reviewing Intelligibility of State-of-the-art Machine Learning Explanations*

An interactive demonstration for the *AI in Action* session of
The Alan Turing Institute's AI UK 2021 conference.

* [Slides](resources/2021_TURING-AI-UK/slides/)

For more details please see the event homepage:
<https://events.fat-forensics.org/2021_turing-ai-uk>.

## September 2020 -- Hands-on Tutorial at ECML-PKDD 2020 ##

[![JOSE](https://jose.theoj.org/papers/d58625bd4c600da866522c879986b18f/status.svg)](https://jose.theoj.org/papers/d58625bd4c600da866522c879986b18f)
[![arXiv](https://img.shields.io/badge/arXiv-2209.03813-red.svg)](https://arxiv.org/abs/2209.03813)
[![ZENODO](https://zenodo.org/badge/DOI/10.5281/zenodo.6395490.svg)](https://doi.org/10.5281/zenodo.6395490)

> **What and How of Machine Learning Transparency:**  
  *Building Bespoke Explainability Tools with Interoperable Algorithmic Components*

A hands-on tutorial to be held at the [ECML-PKDD 2020](https://ecmlpkdd2020.net/)
conference in Ghent, Belgium, from the 14th to the 18th of September 2020.

* [Notebooks](https://github.com/fat-forensics/Surrogates-Tutorial/tree/master/notebooks)
* [Slides](https://github.com/fat-forensics/Surrogates-Tutorial/tree/master/slides)

For more details please see the event homepage:
<https://events.fat-forensics.org/2020_ecml-pkdd>.

To reference this tutorial please use:
```bibtex
@article{sokol2022what,
  title={What and how of machine learning transparency:
         {B}uilding bespoke explainability tools with interoperable
         algorithmic components},
  author={Sokol, Kacper and Hepburn, Alexander and
          Santos-Rodriguez, Raul and Flach, Peter},
  journal={arXiv preprint arXiv:2209.03813},
  year={2022},
  doi={10.48550/arXiv.2209.03813}
}
```
